{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce SciLuigi Case Study Workflow\n",
    "\n",
    "The code for this virtual machine is available [here](https://github.com/pharmbio/bioimg-sciluigi-casestudy), and the direct link to the code for this notebook is available [here](https://github.com/pharmbio/bioimg-sciluigi-casestudy/blob/master/roles/sciluigi_usecase/files/proj/largescale_svm/wffindcost.ipynb).\n",
    "\n",
    "## How to run\n",
    "\n",
    "- To run the workflow, click: \"Cell > Run All\" in the menu above!\n",
    "  - Note that running the full workflow takes a long time. On a Intel i5 dual core laptop, it could take up to ~45 minutes to finish.\n",
    "- For a visualization of the progress, see the \"Luigi Task Visualizer\" browser tab. \n",
    "  - If it is not open, you can also access it via [this link](http://localhost:8082/static/visualiser/index.html#)\n",
    "- To see the dependency graph for the CrossValidate workflow in the Luigi Task Visualizer interface:\n",
    "  - Click the \"CrossValidateWorkflow\" task in the left menu\n",
    "  - Then click the little blue dependency graph icon in the \"Actions\" column, to the far right on the page.\n",
    "  - **Note:** You might need to refresh the browser (Ctrl + R, or Cmd + R), to see the latest state of the workflow.\n",
    "  \n",
    "### Caveats\n",
    "\n",
    "- Please note that in order to re-run the workflow full, you need to go \"Kernel > Restart\", or \"Kernel > Restart & Clear all output\".\n",
    "  - This is because of how Luigi works, by defining tasks as classes, and that if reloading a cell in Jupyter, that would mean re-declaring an already declared class.\n",
    "  - Alternatively, one can just re-start any cells containing only execution code (no class definitions).\n",
    "\n",
    "\n",
    "## Set up imports and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cheminf_components import *\n",
    "import logging\n",
    "import luigi\n",
    "import sciluigi\n",
    "import time\n",
    "\n",
    "log = logging.getLogger('sciluigi-interface')\n",
    "log.setLevel(logging.WARN) # So as not to flood the Jupyter cells with output for the large number of tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the workflow\n",
    "\n",
    "The workflow definition is defined in a subclass of `sciluigi.WorkflowTask`, in the `workflow()` special function, which returns the most downstream task in the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CrossValidateWorkflow(sciluigi.WorkflowTask):\n",
    "    '''\n",
    "    Find the optimal SVM cost values via a grid-search, with cross-validation\n",
    "    '''\n",
    "\n",
    "    # PARAMETERS\n",
    "    dataset_name = luigi.Parameter(default='testrun_dataset')\n",
    "    run_id = luigi.Parameter('test_run_001')\n",
    "    replicate_id = luigi.Parameter('')\n",
    "    replicate_ids = luigi.Parameter(default='r1,r2,r3')\n",
    "    folds_count = luigi.IntParameter(default=10)\n",
    "    min_height = luigi.Parameter(default='1')\n",
    "    max_height = luigi.Parameter(default='3')\n",
    "    test_size = luigi.Parameter('1000')\n",
    "    train_sizes = luigi.Parameter(default='500,1000,2000,4000,8000')\n",
    "    lin_type = luigi.Parameter(default='12') # 12, See: https://www.csie.ntu.edu.tw/~cjlin/liblinear/FAQ.html\n",
    "    randomdatasize_mb = luigi.IntParameter(default='10')\n",
    "    runmode = 'local'\n",
    "    slurm_project = 'N/A'\n",
    "\n",
    "    def workflow(self):\n",
    "        if self.runmode == 'local':\n",
    "            runmode = sciluigi.RUNMODE_LOCAL\n",
    "        elif self.runmode == 'hpc':\n",
    "            runmode = sciluigi.RUNMODE_HPC\n",
    "        elif self.runmode == 'mpi':\n",
    "            runmode = sciluigi.RUNMODE_MPI\n",
    "        else:\n",
    "            raise Exception('Runmode is none of local, hpc, nor mpi. Please fix and try again!')\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        mmtestdata = self.new_task('mmtestdata', ExistingSmiles,\n",
    "                replicate_id='na',\n",
    "                dataset_name=self.dataset_name)\n",
    "        tasks = {}\n",
    "        lowest_rmsds = []\n",
    "        mainwfruns = []\n",
    "        if self.replicate_id != '':\n",
    "            replicate_ids = [self.replicate_id]\n",
    "        else:\n",
    "            replicate_ids = [i for i in self.replicate_ids.split(',')]\n",
    "        for replicate_id in replicate_ids:\n",
    "            tasks[replicate_id] = {}\n",
    "            gensign = self.new_task('gensign_%s' % replicate_id, GenerateSignaturesFilterSubstances,\n",
    "                    replicate_id=replicate_id,\n",
    "                    min_height = self.min_height,\n",
    "                    max_height = self.max_height,\n",
    "                    slurminfo = sciluigi.SlurmInfo(\n",
    "                        runmode=runmode,\n",
    "                        project=self.slurm_project,\n",
    "                        partition='core',\n",
    "                        cores='8',\n",
    "                        time='1:00:00',\n",
    "                        jobname='mmgensign',\n",
    "                        threads='8'\n",
    "                    ))\n",
    "            gensign.in_smiles = mmtestdata.out_smiles\n",
    "            # ----------------------------------------------------------------\n",
    "            create_unique_run_copy = self.new_task('create_unique_run_copy_%s' % self.run_id,\n",
    "                    CreateRunCopy,\n",
    "                    run_id = self.run_id)\n",
    "            create_unique_run_copy.in_file = gensign.out_signatures\n",
    "            # ----------------------------------------------------------------\n",
    "            replcopy = self.new_task('replcopy_%s' % replicate_id, CreateReplicateCopy,\n",
    "                    replicate_id=replicate_id)\n",
    "            replcopy.in_file = create_unique_run_copy.out_copy\n",
    "            # ----------------------------------------------------------------\n",
    "            for train_size in [i for i in self.train_sizes.split(',')]:\n",
    "                samplett = self.new_task('sampletraintest_%s_%s' % (train_size, replicate_id), SampleTrainAndTest,\n",
    "                        replicate_id=replicate_id,\n",
    "                        sampling_method='random',\n",
    "                        test_size=self.test_size,\n",
    "                        train_size=train_size,\n",
    "                        slurminfo = sciluigi.SlurmInfo(\n",
    "                            runmode=runmode,\n",
    "                            project='b2013262',\n",
    "                            partition='core',\n",
    "                            cores='2',\n",
    "                            time='1:00:00',\n",
    "                            jobname='mmsampletraintest_%s_%s' % (train_size, replicate_id),\n",
    "                            threads='1'\n",
    "                        ))\n",
    "                samplett.in_signatures = replcopy.out_copy\n",
    "                # ----------------------------------------------------------------\n",
    "                sprstrain = self.new_task('sparsetrain_%s_%s' % (train_size, replicate_id), CreateSparseTrainDataset,\n",
    "                        replicate_id=replicate_id,\n",
    "                        slurminfo = sciluigi.SlurmInfo(\n",
    "                            runmode=runmode,\n",
    "                            project=self.slurm_project,\n",
    "                            partition='core',\n",
    "                            cores='8',\n",
    "                            time='1-00:00:00', # Took ~16hrs for acd_logd, size: rest(train) - 50000(test)\n",
    "                            jobname='mmsparsetrain_%s_%s' % (train_size, replicate_id),\n",
    "                            threads='8'\n",
    "                        ))\n",
    "                sprstrain.in_traindata = samplett.out_traindata\n",
    "                # ----------------------------------------------------------------\n",
    "                gunzip = self.new_task('gunzip_sparsetrain_%s_%s' % (train_size, replicate_id), UnGzipFile,\n",
    "                        slurminfo = sciluigi.SlurmInfo(\n",
    "                            runmode=runmode,\n",
    "                            project=self.slurm_project,\n",
    "                            partition='core',\n",
    "                            cores='1',\n",
    "                            time='1:00:00',\n",
    "                            jobname='gunzip_sparsetrain_%s_%s' % (train_size, replicate_id),\n",
    "                            threads='1'\n",
    "                        ))\n",
    "                gunzip.in_gzipped = sprstrain.out_sparse_traindata\n",
    "                # ----------------------------------------------------------------\n",
    "                cntlines = self.new_task('countlines_%s_%s' % (train_size, replicate_id), CountLines,\n",
    "                        slurminfo = sciluigi.SlurmInfo(\n",
    "                            runmode=runmode,\n",
    "                            project=self.slurm_project,\n",
    "                            partition='core',\n",
    "                            cores='1',\n",
    "                            time='15:00',\n",
    "                            jobname='gunzip_sparsetrain_%s_%s' % (train_size, replicate_id),\n",
    "                            threads='1'\n",
    "                        ))\n",
    "                cntlines.in_file = gunzip.out_ungzipped\n",
    "                # ----------------------------------------------------------------\n",
    "                genrandomdata= self.new_task('genrandomdata_%s_%s' % (train_size, replicate_id), CreateRandomData,\n",
    "                        size_mb=self.randomdatasize_mb,\n",
    "                        replicate_id=replicate_id,\n",
    "                        slurminfo = sciluigi.SlurmInfo(\n",
    "                            runmode=runmode,\n",
    "                            project=self.slurm_project,\n",
    "                            partition='core',\n",
    "                            cores='1',\n",
    "                            time='1:00:00',\n",
    "                            jobname='genrandomdata_%s_%s' % (train_size, replicate_id),\n",
    "                            threads='1'\n",
    "                        ))\n",
    "                genrandomdata.in_basepath = gunzip.out_ungzipped\n",
    "                # ----------------------------------------------------------------\n",
    "                shufflelines = self.new_task('shufflelines_%s_%s' % (train_size, replicate_id), ShuffleLines,\n",
    "                        slurminfo = sciluigi.SlurmInfo(\n",
    "                            runmode=runmode,\n",
    "                            project=self.slurm_project,\n",
    "                            partition='core',\n",
    "                            cores='1',\n",
    "                            time='15:00',\n",
    "                            jobname='shufflelines_%s_%s' % (train_size, replicate_id),\n",
    "                            threads='1'\n",
    "                        ))\n",
    "                shufflelines.in_randomdata = genrandomdata.out_random\n",
    "                shufflelines.in_file = gunzip.out_ungzipped\n",
    "                # ----------------------------------------------------------------\n",
    "\n",
    "                costseq = ['0.0001', '0.0005', '0.001', '0.005', '0.01', '0.05', '0.1', '0.25', '0.5', '0.75', '1', '2', '3', '4', '5' ] + [str(int(10**p)) for p in xrange(1,12)]\n",
    "                # Branch the workflow into one branch per fold\n",
    "                for fold_idx in xrange(self.folds_count):\n",
    "                    tasks[replicate_id][fold_idx] = {}\n",
    "                    # Init tasks\n",
    "                    create_folds = self.new_task('create_fold%02d_%s_%s' % (fold_idx, train_size, replicate_id), CreateFolds,\n",
    "                            fold_index = fold_idx,\n",
    "                            folds_count = self.folds_count,\n",
    "                            seed = 0.637,\n",
    "                            slurminfo = sciluigi.SlurmInfo(\n",
    "                                runmode=runmode,\n",
    "                                project=self.slurm_project,\n",
    "                                partition='core',\n",
    "                                cores='1',\n",
    "                                time='1:00:00',\n",
    "                                jobname='create_fold%02d_%s_%s' % (fold_idx, train_size, replicate_id),\n",
    "                                threads='1'\n",
    "                            ))\n",
    "                    for cost in costseq:\n",
    "                        tasks[replicate_id][fold_idx][cost] = {}\n",
    "                        create_folds.in_dataset = shufflelines.out_shuffled\n",
    "                        create_folds.in_linecount = cntlines.out_linecount\n",
    "                        # -------------------------------------------------\n",
    "                        train_lin = self.new_task('trainlin_fold_%d_cost_%s_%s_%s' % (fold_idx, cost, train_size, replicate_id), TrainLinearModel,\n",
    "                                replicate_id = replicate_id,\n",
    "                                lin_type = self.lin_type,\n",
    "                                lin_cost = cost,\n",
    "                                slurminfo = sciluigi.SlurmInfo(\n",
    "                                    runmode=runmode,\n",
    "                                    project=self.slurm_project,\n",
    "                                    partition='core',\n",
    "                                    cores='1',\n",
    "                                    time='4-00:00:00',\n",
    "                                    jobname='trnlin_f%02d_c%s_%s_%s' % (fold_idx, cost, train_size, replicate_id),\n",
    "                                    threads='1'\n",
    "                                ))\n",
    "                        train_lin.in_traindata = create_folds.out_traindata\n",
    "                        # -------------------------------------------------\n",
    "                        pred_lin = self.new_task('predlin_fold_%d_cost_%s_%s_%s' % (fold_idx, cost, train_size, replicate_id), PredictLinearModel,\n",
    "                                replicate_id = replicate_id,\n",
    "                                slurminfo = sciluigi.SlurmInfo(\n",
    "                                    runmode=runmode,\n",
    "                                    project=self.slurm_project,\n",
    "                                    partition='core',\n",
    "                                    cores='1',\n",
    "                                    time='8:00:00',\n",
    "                                    jobname='predlin_f%02d_c%s_%s_%s' % (fold_idx, cost, train_size, replicate_id),\n",
    "                                    threads='1'\n",
    "                                ))\n",
    "                        pred_lin.in_model = train_lin.out_model\n",
    "                        pred_lin.in_sparse_testdata = create_folds.out_testdata\n",
    "                        # -------------------------------------------------\n",
    "                        assess_lin = self.new_task('assesslin_fold_%d_cost_%s_%s_%s' % (fold_idx, cost, train_size, replicate_id), AssessLinearRMSD,\n",
    "                                lin_cost = cost,\n",
    "                                slurminfo = sciluigi.SlurmInfo(\n",
    "                                    runmode=runmode,\n",
    "                                    project=self.slurm_project,\n",
    "                                    partition='core',\n",
    "                                    cores='1',\n",
    "                                    time='15:00',\n",
    "                                    jobname='assesslin_f%02d_c%s_%s_%s' % (fold_idx, cost, train_size, replicate_id),\n",
    "                                    threads='1'\n",
    "                                ))\n",
    "                        assess_lin.in_model = train_lin.out_model\n",
    "                        assess_lin.in_sparse_testdata = create_folds.out_testdata\n",
    "                        assess_lin.in_prediction = pred_lin.out_prediction\n",
    "                        # -------------------------------------------------\n",
    "                        tasks[replicate_id][fold_idx][cost] = {}\n",
    "                        tasks[replicate_id][fold_idx][cost]['create_folds'] = create_folds\n",
    "                        tasks[replicate_id][fold_idx][cost]['train_linear'] = train_lin\n",
    "                        tasks[replicate_id][fold_idx][cost]['predict_linear'] = pred_lin\n",
    "                        tasks[replicate_id][fold_idx][cost]['assess_linear'] = assess_lin\n",
    "\n",
    "                # Tasks for calculating average RMSD and finding the cost with lowest RMSD\n",
    "                avgrmsd_tasks = {}\n",
    "                for cost in costseq:\n",
    "                    # Calculate the average RMSD for each cost value\n",
    "                    average_rmsd = self.new_task('average_rmsd_cost_%s_%s_%s' % (cost, train_size, replicate_id), CalcAverageRMSDForCost,\n",
    "                            lin_cost=cost)\n",
    "                    average_rmsd.in_assessments = [tasks[replicate_id][fold_idx][cost]['assess_linear'].out_assessment for fold_idx in xrange(self.folds_count)]\n",
    "                    avgrmsd_tasks[cost] = average_rmsd\n",
    "                # --------------------------------------------------------------------------------\n",
    "                sel_lowest_rmsd = self.new_task('select_lowest_rmsd_%s_%s' % (train_size, replicate_id), SelectLowestRMSD)\n",
    "                sel_lowest_rmsd.in_values = [average_rmsd.out_rmsdavg for average_rmsd in avgrmsd_tasks.values()]\n",
    "                # --------------------------------------------------------------------------------\n",
    "                run_id = 'mainwfrun_liblinear_%s_tst%s_trn%s_%s' % (self.dataset_name, self.test_size, train_size, replicate_id)\n",
    "                mainwfrun = self.new_task('mainwfrun_%s_%s' % (train_size, replicate_id), MainWorkflowRunner,\n",
    "                        dataset_name=self.dataset_name,\n",
    "                        run_id=run_id,\n",
    "                        replicate_id=replicate_id,\n",
    "                        sampling_method='random',\n",
    "                        train_method='liblinear',\n",
    "                        train_size=train_size,\n",
    "                        test_size=self.test_size,\n",
    "                        lin_type=self.lin_type,\n",
    "                        slurm_project=self.slurm_project,\n",
    "                        parallel_lin_train=False,\n",
    "                        runmode=self.runmode)\n",
    "                mainwfrun.in_lowestrmsd = sel_lowest_rmsd.out_lowest\n",
    "                # --------------------------------------------------------------------------------\n",
    "                # Collect one lowest rmsd per train size\n",
    "                lowest_rmsds.append(sel_lowest_rmsd)\n",
    "\n",
    "                mainwfruns.append(mainwfrun)\n",
    "\n",
    "        # --------------------------------------------------------------------------------\n",
    "        mergedreport = self.new_task('merged_report_%s_%s' % (self.dataset_name, self.run_id), MergedDataReport,\n",
    "                run_id = self.run_id)\n",
    "        mergedreport.in_reports = [t.out_report for t in mainwfruns]\n",
    "\n",
    "        return mergedreport\n",
    "\n",
    "# ================================================================================\n",
    "\n",
    "class MainWorkflowRunner(sciluigi.Task):\n",
    "    # Parameters\n",
    "    dataset_name = luigi.Parameter()\n",
    "    run_id = luigi.Parameter()\n",
    "    replicate_id =luigi.Parameter()\n",
    "    sampling_method = luigi.Parameter()\n",
    "    train_method = luigi.Parameter()\n",
    "    train_size = luigi.Parameter()\n",
    "    test_size = luigi.Parameter()\n",
    "    lin_type = luigi.Parameter()\n",
    "    slurm_project = luigi.Parameter()\n",
    "    parallel_lin_train = luigi.BoolParameter()\n",
    "    runmode = luigi.Parameter()\n",
    "    \n",
    "    # In-ports (defined as fields accepting sciluigi.TargetInfo objects)\n",
    "    in_lowestrmsd = None\n",
    "    \n",
    "    # Out-ports\n",
    "    def out_done(self):\n",
    "        return sciluigi.TargetInfo(self, self.in_lowestrmsd().path + '.mainwf_done')\n",
    "    def out_report(self):\n",
    "        outf_path = 'data/' + self.run_id + '/testrun_dataset_liblinear_datareport.csv'\n",
    "        return sciluigi.TargetInfo(self, outf_path) # We manually re-create the filename that this should have\n",
    "    \n",
    "    # Task implementation\n",
    "    def run(self):\n",
    "        with self.in_lowestrmsd().open() as infile:\n",
    "            records = sciluigi.recordfile_to_dict(infile)\n",
    "            lowest_cost = records['lowest_cost']\n",
    "        self.ex('python wfmm.py' +\n",
    "                ' --dataset-name=%s' % self.dataset_name +\n",
    "                ' --run-id=%s' % self.run_id +\n",
    "                ' --replicate-id=%s' % self.replicate_id +\n",
    "                ' --sampling-method=%s' % self.sampling_method +\n",
    "                ' --train-method=%s' % self.train_method +\n",
    "                ' --train-size=%s' % self.train_size +\n",
    "                ' --test-size=%s' % self.test_size +\n",
    "                ' --lin-type=%s' % self.lin_type +\n",
    "                ' --lin-cost=%s' % lowest_cost +\n",
    "                ' --slurm-project=%s' % self.slurm_project +\n",
    "                ' --runmode=%s' % self.runmode)\n",
    "        with self.out_done().open('w') as donefile:\n",
    "            donefile.write('Done!\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the workflow\n",
    "\n",
    "Execute the workflow locally (using the luigi daemon which runs in the background), starting with the `CrossValidateWorkflow` workflow class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print time.strftime('%Y-%m-%d %H:%M:%S: ') + 'Workflow started ...'\n",
    "sciluigi.run(cmdline_args=['--scheduler-host=localhost', '--workers=4'], main_task_cls=CrossValidateWorkflow)\n",
    "print time.strftime('%Y-%m-%d %H:%M:%S: ') + 'Workflow finished!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse result data from workflow into python dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from matplotlib.pyplot import *\n",
    "\n",
    "merged_report_filepath = 'data/test_run_001_merged_report.csv'\n",
    "replicate_ids = ['r1','r2','r3']\n",
    "rowdicts = []\n",
    "\n",
    "\n",
    "# Collect data in one dict per row in the csv file\n",
    "with open(merged_report_filepath) as infile:\n",
    "    csvrd = csv.reader(infile, delimiter=',')\n",
    "    for rid, row in enumerate(csvrd):\n",
    "        if rid == 0:\n",
    "            headerrow = row\n",
    "        else:\n",
    "            rowdicts.append({headerrow[i]:v for i, v in enumerate(row)})\n",
    "        \n",
    "# Collect the training sizes\n",
    "train_sizes = []\n",
    "for r  in rowdicts:\n",
    "    if r['replicate_id'] == 'r1':\n",
    "        train_sizes.append(r['train_size'])\n",
    "\n",
    "# Collect the training times (in seconds)\n",
    "train_times = {}\n",
    "rmsd_values = {}\n",
    "for repl_id in replicate_ids: \n",
    "    train_times[repl_id] = []\n",
    "    rmsd_values[repl_id] = []\n",
    "    for r in rowdicts:\n",
    "        if r['replicate_id'] == repl_id:\n",
    "            train_times[repl_id].append(r['train_time_sec'])\n",
    "            rmsd_values[repl_id].append(r['rmsd'])\n",
    "\n",
    "# Calculate average values for the training time\n",
    "train_times_avg = []\n",
    "for i in range(0, len(train_times['r1'])):\n",
    "    train_times_avg.append(0.0)\n",
    "    for repl_id in replicate_ids:\n",
    "        train_times_avg[i] += float(train_times[repl_id][i])\n",
    "    train_times_avg[i] =  train_times_avg[i] / float(len(replicate_ids))\n",
    "\n",
    "# Calculate average values for the RMSD values\n",
    "rmsd_values_avg = []\n",
    "for i in range(0, len(rmsd_values['r1'])):\n",
    "    rmsd_values_avg.append(0.0)\n",
    "    for repl_id in replicate_ids:\n",
    "        rmsd_values_avg[i] += float(rmsd_values[repl_id][i])\n",
    "    rmsd_values_avg[i] =  rmsd_values_avg[i] / float(len(replicate_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print values (Train sizes, train times and RMSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"-\"*60\n",
    "print 'Train sizes:        ' + ', '.join(train_sizes) + ' molecules'\n",
    "print ''\n",
    "print 'RMSD values: '\n",
    "for rid in range(1,4):\n",
    "    print '      Replicate %d: ' % rid + ', '.join(['%.2f' % float(v) for v in rmsd_values['r%d' % rid]])\n",
    "print ''\n",
    "print 'Train times: '\n",
    "for rid in range(1,4):\n",
    "    print '      Replicate %d: ' % rid + ', '.join(train_times['r%d' % rid]) + ' seconds'\n",
    "\n",
    "print ''\n",
    "print 'RMSD values (avg): ' + ', '.join(['%.2f' % x for x in rmsd_values_avg])\n",
    "print 'Train times (avg): ' + ', '.join(['%.2f' % x for x in train_times_avg]) + ' seconds'\n",
    "print \"-\"*60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot train time and RMSD against training size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize plotting figure\n",
    "fig = figure()\n",
    "\n",
    "# Set up subplot for RMSD values\n",
    "subpl1 = fig.add_subplot(1,1,1)\n",
    "# x-axis\n",
    "xticks = [500,1000,2000,4000,8000]\n",
    "subpl1.set_xscale('log')\n",
    "subpl1.set_xlim([500,8000])\n",
    "subpl1.set_xticks(ticks=xticks)\n",
    "subpl1.set_xticklabels([str(l) for l in xticks])\n",
    "subpl1.set_xlabel('Training set size (number of molecules)')\n",
    "# y-axis\n",
    "subpl1.set_ylim([0,1])\n",
    "subpl1.set_ylabel('RMSD for test prediction')\n",
    "# plot\n",
    "subpl1.plot(train_sizes, \n",
    "     rmsd_values_avg,\n",
    "     label='RMSD for test prediction',\n",
    "     marker='.',\n",
    "     color='k',\n",
    "     linestyle='-')\n",
    "\n",
    "# Set up subplot for training times\n",
    "subpl2 = subpl1.twinx()\n",
    "# y-axis\n",
    "yticks = [0.01,0.02,0.03,0.05,0.1,0.2,0.3,0.4,0.5]\n",
    "subpl2.set_ylim([0.01,0.5])\n",
    "subpl2.set_yscale('log')\n",
    "subpl2.set_yticks(ticks=yticks)\n",
    "subpl2.set_yticklabels([str(int(l*1000)) for l in yticks])\n",
    "subpl2.set_ylabel('Training time (milliseconds)')\n",
    "subpl2.tick_params(axis='y', colors='r')\n",
    "subpl2.yaxis.label.set_color('r')\n",
    "subpl2.spines['right'].set_color('red')\n",
    "# plot\n",
    "subpl2.plot(train_sizes, \n",
    "     train_times_avg,\n",
    "     label='Training time (seconds)',\n",
    "     marker='.',\n",
    "     color='r',\n",
    "     linestyle='-')\n",
    "\n",
    "subpl1.legend(loc='upper left', fontsize=9)\n",
    "subpl2.legend(bbox_to_anchor=(0, 0.9), loc='upper left', fontsize=9)\n",
    "\n",
    "show() # Display the plot"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
